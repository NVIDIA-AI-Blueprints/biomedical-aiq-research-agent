name: Deploy and Test Biomedical AI-Q Research Agent

on:
  push:
    branches: [ main, '*-dev' ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  NVIDIA_API_KEY: ${{ secrets.NGC_API_KEY }}
  NGC_API_KEY: ${{ secrets.NGC_API_KEY }}
  TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
  RAG_VERSION: v2.2.1

jobs:
  # ============================================
  # Job 1: All Cloud Mode
  # All NIMs use hosted API endpoints
  # ============================================
  all-cloud:
    name: All Cloud Mode Test
    runs-on: arc-runner-set-oke-org-poc-1-gpu
    timeout-minutes: 60
    
    steps:
      - name: "[CHECKOUT] Repository"
        uses: actions/checkout@v4
      
      - name: "[DOCKER] Setup Buildx"
        uses: docker/setup-buildx-action@v3
      
      - name: "[CACHE] Restore Docker Images"
        uses: actions/cache@v4
        with:
          path: /tmp/docker-cache
          key: docker-images-all-cloud-${{ env.RAG_VERSION }}-${{ hashFiles('deploy/compose/docker-compose.yaml') }}
          restore-keys: |
            docker-images-all-cloud-${{ env.RAG_VERSION }}-
            docker-images-all-cloud-
      
      - name: "[CACHE] Load Docker Images"
        run: |
          if [ -d "/tmp/docker-cache" ] && [ "$(ls -A /tmp/docker-cache)" ]; then
            echo "Loading cached Docker images..."
            for img in /tmp/docker-cache/*.tar; do
              if [ -f "$img" ]; then
                docker load -i "$img" || true
              fi
            done
            echo "Cached images loaded"
          else
            echo "No cached images found"
          fi
      
      - name: "[AUTH] Login to NVIDIA Container Registry"
        run: |
          echo "${{ secrets.NGC_API_KEY }}" | docker login nvcr.io -u '$oauthtoken' --password-stdin
      
      - name: "[CONFIG] Set Environment Variables for All Cloud Mode"
        run: |
          echo "USERID=$(id -u)" >> $GITHUB_ENV
          echo "APP_LLM_MODELNAME=nvidia/llama-3.3-nemotron-super-49b-v1" >> $GITHUB_ENV
          echo "APP_EMBEDDINGS_MODELNAME=nvidia/llama-3.2-nv-embedqa-1b-v2" >> $GITHUB_ENV
          echo "APP_RANKING_MODELNAME=nvidia/llama-3.2-nv-rerankqa-1b-v2" >> $GITHUB_ENV
          echo "APP_EMBEDDINGS_SERVERURL=" >> $GITHUB_ENV
          echo "APP_LLM_SERVERURL=" >> $GITHUB_ENV
          echo "APP_RANKING_SERVERURL=" >> $GITHUB_ENV
          echo "EMBEDDING_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1" >> $GITHUB_ENV
          echo "PADDLE_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/baidu/paddleocr" >> $GITHUB_ENV
          echo "PADDLE_INFER_PROTOCOL=http" >> $GITHUB_ENV
          echo "YOLOX_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-page-elements-v2" >> $GITHUB_ENV
          echo "YOLOX_INFER_PROTOCOL=http" >> $GITHUB_ENV
          echo "YOLOX_GRAPHIC_ELEMENTS_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-graphic-elements-v1" >> $GITHUB_ENV
          echo "YOLOX_GRAPHIC_ELEMENTS_INFER_PROTOCOL=http" >> $GITHUB_ENV
          echo "YOLOX_TABLE_STRUCTURE_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-table-structure-v1" >> $GITHUB_ENV
          echo "YOLOX_TABLE_STRUCTURE_INFER_PROTOCOL=http" >> $GITHUB_ENV
          echo "ENABLE_RERANKER=false" >> $GITHUB_ENV
          echo "ENABLE_NV_INGEST_BATCH_MODE=true" >> $GITHUB_ENV
          echo "AIRA_HOSTED_NIMS=true" >> $GITHUB_ENV
          echo "MOLMIM_ENDPOINT_URL=https://health.api.nvidia.com/v1/biology/nvidia/molmim/generate" >> $GITHUB_ENV
          echo "DIFFDOCK_ENDPOINT_URL=https://health.api.nvidia.com/v1/biology/mit/diffdock" >> $GITHUB_ENV
      
      - name: "[DOWNLOAD] Clone RAG Blueprint"
        run: |
          git clone --branch ${{ env.RAG_VERSION }} https://github.com/NVIDIA-AI-Blueprints/rag.git
      
      - name: "[DEPLOY] RAG Vector Database"
        run: |
          docker compose -f rag/deploy/compose/vectordb.yaml up -d
          sleep 30
      
      - name: "[DEPLOY] RAG Ingestion Server"
        run: |
          docker compose -f rag/deploy/compose/docker-compose-ingestor-server.yaml up -d
          sleep 30
      
      - name: "[DEPLOY] RAG Server"
        run: |
          docker compose -f rag/deploy/compose/docker-compose-rag-server.yaml up -d
          sleep 30
      
      - name: "[DEPLOY] AIRA Services"
        run: |
          docker compose -f deploy/compose/docker-compose.yaml --profile aira up -d
          sleep 30
      
      - name: "[HEALTH] Wait and Check Services"
        run: |
          sleep 60
          docker ps --format "table {{.Names}}\t{{.Status}}"
          curl -f http://localhost:3001 > /dev/null 2>&1 && echo "Frontend OK" || echo "Frontend FAIL"
          curl -f http://localhost:8051/docs > /dev/null 2>&1 && echo "Backend OK" || echo "Backend FAIL"
      
      - name: "[TEST] Quick Functional Test"
        run: |
          curl -X POST http://localhost:8051/v1/collections \
            -H 'Content-Type: application/json' \
            -d '["test_all_cloud"]' || echo "Test execution attempted"
      
      - name: "[CACHE] Save Docker Images"
        if: always()
        run: |
          mkdir -p /tmp/docker-cache
          docker images --format "{{.Repository}}:{{.Tag}}" | grep -E "(nvcr.io|milvus|redis)" | while read img; do
            filename=$(echo "$img" | tr '/:' '_')
            if [ ! -f "/tmp/docker-cache/${filename}.tar" ]; then
              docker save -o "/tmp/docker-cache/${filename}.tar" "$img" || true
            fi
          done
          echo "Docker images saved to cache"
      
      - name: "[CLEANUP] Stop Services"
        if: always()
        run: |
          docker compose -f deploy/compose/docker-compose.yaml --profile aira down || true
          docker compose -f rag/deploy/compose/docker-compose-rag-server.yaml down || true
          docker compose -f rag/deploy/compose/docker-compose-ingestor-server.yaml down || true
          docker compose -f rag/deploy/compose/vectordb.yaml down || true
          docker volume prune -f || true
      
      - name: "[OUTPUT] Save Test Result"
        if: always()
        run: |
          echo "all-cloud-status=${{ job.status }}" >> $GITHUB_OUTPUT
        id: result

  # ============================================
  # Job 2: Local Ingestion Mode
  # Deploy ingestion NIMs locally, others use hosted APIs
  # ============================================
  local-ingestion:
    name: Local Ingestion Mode Test
    runs-on: arc-runner-set-oke-org-poc-1-gpu
    timeout-minutes: 60
    
    steps:
      - name: "[CHECKOUT] Repository"
        uses: actions/checkout@v4
      
      - name: "[DOCKER] Setup Buildx"
        uses: docker/setup-buildx-action@v3
      
      - name: "[CACHE] Restore Docker Images"
        uses: actions/cache@v4
        with:
          path: /tmp/docker-cache
          key: docker-images-local-ingestion-${{ env.RAG_VERSION }}-${{ hashFiles('deploy/compose/docker-compose.yaml') }}
          restore-keys: |
            docker-images-local-ingestion-${{ env.RAG_VERSION }}-
            docker-images-local-ingestion-
      
      - name: "[CACHE] Load Docker Images"
        run: |
          if [ -d "/tmp/docker-cache" ] && [ "$(ls -A /tmp/docker-cache)" ]; then
            echo "Loading cached Docker images..."
            for img in /tmp/docker-cache/*.tar; do
              if [ -f "$img" ]; then
                docker load -i "$img" || true
              fi
            done
            echo "Cached images loaded"
          else
            echo "No cached images found"
          fi
      
      - name: "[AUTH] Login to NVIDIA Container Registry"
        run: |
          echo "${{ secrets.NGC_API_KEY }}" | docker login nvcr.io -u '$oauthtoken' --password-stdin
      
      - name: "[CONFIG] Set Environment Variables for Local Ingestion Mode"
        run: |
          echo "USERID=$(id -u)" >> $GITHUB_ENV
          echo "APP_LLM_MODELNAME=nvidia/llama-3.3-nemotron-super-49b-v1" >> $GITHUB_ENV
          echo "APP_LLM_SERVERURL=" >> $GITHUB_ENV
          echo "APP_RANKING_SERVERURL=" >> $GITHUB_ENV
          echo "APP_EMBEDDINGS_MODELNAME=nvidia/llama-3.2-nv-embedqa-1b-v2" >> $GITHUB_ENV
          echo "APP_EMBEDDINGS_SERVERURL=nemoretriever-embedding-ms:8000" >> $GITHUB_ENV
          echo "EMBEDDING_NIM_ENDPOINT=http://nemoretriever-embedding-ms:8000/v1" >> $GITHUB_ENV
          echo "PADDLE_INFER_PROTOCOL=grpc" >> $GITHUB_ENV
          echo "PADDLE_GRPC_ENDPOINT=paddle:8001" >> $GITHUB_ENV
          echo "YOLOX_INFER_PROTOCOL=grpc" >> $GITHUB_ENV
          echo "YOLOX_GRPC_ENDPOINT=page-elements:8001" >> $GITHUB_ENV
          echo "YOLOX_GRAPHIC_ELEMENTS_GRPC_ENDPOINT=graphic-elements:8001" >> $GITHUB_ENV
          echo "YOLOX_GRAPHIC_ELEMENTS_INFER_PROTOCOL=grpc" >> $GITHUB_ENV
          echo "YOLOX_TABLE_STRUCTURE_GRPC_ENDPOINT=table-structure:8001" >> $GITHUB_ENV
          echo "YOLOX_TABLE_STRUCTURE_INFER_PROTOCOL=grpc" >> $GITHUB_ENV
          echo "ENABLE_RERANKER=false" >> $GITHUB_ENV
          echo "ENABLE_NV_INGEST_BATCH_MODE=true" >> $GITHUB_ENV
          echo "AIRA_HOSTED_NIMS=true" >> $GITHUB_ENV
          echo "MOLMIM_ENDPOINT_URL=https://health.api.nvidia.com/v1/biology/nvidia/molmim/generate" >> $GITHUB_ENV
          echo "DIFFDOCK_ENDPOINT_URL=https://health.api.nvidia.com/v1/biology/mit/diffdock" >> $GITHUB_ENV
      
      - name: "[DOWNLOAD] Clone RAG Blueprint"
        run: |
          git clone --branch ${{ env.RAG_VERSION }} https://github.com/NVIDIA-AI-Blueprints/rag.git
      
      - name: "[DEPLOY] Local Ingestion NIMs"
        run: |
          docker compose -f rag/deploy/compose/nims.yaml --profile ingest up -d
          echo "Wait for ingestion NIMs to initialize..."
          sleep 60
      
      - name: "[VERIFY] Ingestion NIMs Status"
        run: |
          docker ps --format "table {{.Names}}\t{{.Status}}"
          docker ps | grep -E "(nemoretriever-embedding-ms|page-elements|paddle|table-structure|graphic-elements)" || echo "Warning: Some ingestion NIMs not found"
      
      - name: "[DEPLOY] RAG Vector Database"
        run: |
          docker compose -f rag/deploy/compose/vectordb.yaml up -d
          sleep 30
      
      - name: "[DEPLOY] RAG Ingestion Server"
        run: |
          docker compose -f rag/deploy/compose/docker-compose-ingestor-server.yaml up -d
          sleep 30
      
      - name: "[DEPLOY] RAG Server"
        run: |
          docker compose -f rag/deploy/compose/docker-compose-rag-server.yaml up -d
          sleep 30
      
      - name: "[DEPLOY] AIRA Services"
        run: |
          docker compose -f deploy/compose/docker-compose.yaml --profile aira up -d
          sleep 30
      
      - name: "[HEALTH] Wait and Check Services"
        run: |
          sleep 60
          docker ps --format "table {{.Names}}\t{{.Status}}"
          curl -f http://localhost:3001 > /dev/null 2>&1 && echo "Frontend OK" || echo "Frontend FAIL"
          curl -f http://localhost:8051/docs > /dev/null 2>&1 && echo "Backend OK" || echo "Backend FAIL"
      
      - name: "[TEST] Quick Functional Test"
        run: |
          curl -X POST http://localhost:8051/v1/collections \
            -H 'Content-Type: application/json' \
            -d '["test_local_ingestion"]' || echo "Test execution attempted"
      
      - name: "[CACHE] Save Docker Images"
        if: always()
        run: |
          mkdir -p /tmp/docker-cache
          docker images --format "{{.Repository}}:{{.Tag}}" | grep -E "(nvcr.io|milvus|redis)" | while read img; do
            filename=$(echo "$img" | tr '/:' '_')
            if [ ! -f "/tmp/docker-cache/${filename}.tar" ]; then
              docker save -o "/tmp/docker-cache/${filename}.tar" "$img" || true
            fi
          done
          echo "Docker images saved to cache"
      
      - name: "[CLEANUP] Stop Services"
        if: always()
        run: |
          docker compose -f deploy/compose/docker-compose.yaml --profile aira down || true
          docker compose -f rag/deploy/compose/docker-compose-rag-server.yaml down || true
          docker compose -f rag/deploy/compose/docker-compose-ingestor-server.yaml down || true
          docker compose -f rag/deploy/compose/vectordb.yaml down || true
          docker compose -f rag/deploy/compose/nims.yaml down || true
          docker volume prune -f || true
      
      - name: "[OUTPUT] Save Test Result"
        if: always()
        run: |
          echo "local-ingestion-status=${{ job.status }}" >> $GITHUB_OUTPUT
        id: result

  # ============================================
  # Job 3: Summary
  # Collect and report results from both modes
  # ============================================
  summary:
    name: Test Summary Report
    runs-on: ubuntu-latest
    needs: [all-cloud, local-ingestion]
    if: always()
    
    steps:
      - name: "[SETUP] Install Dependencies"
        run: |
          sudo apt-get update
          sudo apt-get install -y python3 python3-pip mailutils

      - name: "[SUMMARY] Generate Report"
        run: |
          echo "# Deployment Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Job Results
          if [ "${{ needs.all-cloud.result }}" = "success" ]; then
            echo "[PASS] **All Cloud Mode** - Execution completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "[FAIL] **All Cloud Mode** - Execution failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.local-ingestion.result }}" = "success" ]; then
            echo "[PASS] **Local Ingestion Mode** - Execution completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "[FAIL] **Local Ingestion Mode** - Execution failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Summary Table
          echo "## Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Deployment Mode | Status | Description |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------------|--------|-------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Cloud | ${{ needs.all-cloud.result }} | All NIMs use hosted APIs |" >> $GITHUB_STEP_SUMMARY
          echo "| Local Ingestion | ${{ needs.local-ingestion.result }} | Local ingestion NIMs + hosted APIs |" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Build Info
          echo "### Build Information" >> $GITHUB_STEP_SUMMARY
          echo "- **Repository:** ${{ github.repository }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **RAG Version:** ${{ env.RAG_VERSION }}" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Overall Status
          if [ "${{ needs.all-cloud.result }}" = "success" ] && [ "${{ needs.local-ingestion.result }}" = "success" ]; then
            echo "### [SUCCESS] Overall Status" >> $GITHUB_STEP_SUMMARY
            echo "Both deployment modes completed successfully" >> $GITHUB_STEP_SUMMARY
            exit 0
          elif [ "${{ needs.all-cloud.result }}" = "success" ] || [ "${{ needs.local-ingestion.result }}" = "success" ]; then
            echo "### [PARTIAL] Overall Status" >> $GITHUB_STEP_SUMMARY
            echo "At least one deployment mode completed successfully" >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "### [FAILURE] Overall Status" >> $GITHUB_STEP_SUMMARY
            echo "Both deployment modes failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
      